services:
  vllm:
    command: # python3 -m vllm.entrypoints.openai.api_server
      --model ${MODEL_NAME:-nvidia/Mistral-NeMo-Minitron-8B-Instruct}
      --dtype ${DATATYPE:-auto}
      --tensor-parallel-size ${NUM_GPUS:-1}
      --gpu-memory-utilization ${GPU_MEMORY_UTILIZATION:-0.9}
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              count: all
              driver: nvidia
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
      - TZ=${TZ:-}
      - VLLM_API_KEY=${VLLM_API_KEY:-}
    hostname: vllm
    image: vllm/vllm-openai:latest
    ipc: host
    ports:
      - "${PORT:-8000}:8000"
    restart: on-failure:5
    volumes:
      - ${HOME:-.}/.cache/huggingface/hub:/root/.cache/huggingface/hub
